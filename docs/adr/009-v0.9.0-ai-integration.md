# ADR 009 - v0.9.0 AI Integration Strategy

**Status**: Proposed

**Date**: 2025-01-17

**Authors**: Felix Geelhaar

## Context

cclint currently provides rule-based validation with static fixes. However, some violations require nuanced understanding:

1. **Generic instruction rewriting**: Turning "follow best practices" into project-specific guidance requires understanding the codebase
2. **Missing section generation**: Suggesting Architecture content requires analyzing actual code structure
3. **Context-aware improvements**: Recommendations that fit the project's style and tech stack

AI integration can provide intelligent suggestions that static rules cannot. Given that cclint is a tool for CLAUDE.md files (Claude AI context), using Claude to improve those files creates a powerful feedback loop.

### Requirements

- Opt-in only (privacy-respecting)
- Works without API keys for core functionality
- Local LLM support for offline/private use
- Clear indication when AI is being used
- Cost-conscious (minimize tokens)

## Decision

Implement AI integration as an optional enhancement layer that augments (not replaces) rule-based linting.

### AI Provider Architecture

```
┌──────────────────────────────────────────────────────────────┐
│                    AI Provider Interface                      │
├──────────────────────────────────────────────────────────────┤
│  suggest(context: AIContext): Promise<Suggestion[]>          │
│  rewrite(content: string, instruction: string): Promise<str> │
│  analyze(codebase: string[]): Promise<Analysis>              │
└──────────────────────────────────────────────────────────────┘
                              ▲
              ┌───────────────┼───────────────┐
              │               │               │
┌─────────────▼─────┐ ┌──────▼──────┐ ┌──────▼──────┐
│  Claude Provider  │ │   OpenAI    │ │   Local     │
│  (Anthropic API)  │ │  Provider   │ │  Provider   │
│                   │ │             │ │ (Ollama)    │
└───────────────────┘ └─────────────┘ └─────────────┘
```

### Feature Set

#### 1. AI Suggestions (`cclint suggest`)

```bash
# Analyze CLAUDE.md and suggest improvements
cclint suggest CLAUDE.md

# Generate missing sections
cclint suggest --generate-missing

# Rewrite generic instructions
cclint suggest --rewrite-generic

# Full analysis with codebase context
cclint suggest --with-codebase
```

#### 2. AI-Enhanced Fixes (`--ai` flag)

```bash
# Lint with AI-powered fix suggestions
cclint lint CLAUDE.md --fix --ai

# Interactive mode with AI explanations
cclint lint CLAUDE.md --interactive --ai
```

#### 3. Codebase Analysis (`cclint analyze`)

```bash
# Analyze codebase and suggest CLAUDE.md content
cclint analyze .

# Output as draft CLAUDE.md
cclint analyze . --output CLAUDE.draft.md
```

### Provider Configuration

```json
{
  "ai": {
    "enabled": false,
    "provider": "claude",
    "providers": {
      "claude": {
        "apiKey": "${ANTHROPIC_API_KEY}",
        "model": "claude-3-5-sonnet-20241022",
        "maxTokens": 4096
      },
      "openai": {
        "apiKey": "${OPENAI_API_KEY}",
        "model": "gpt-4-turbo",
        "maxTokens": 4096
      },
      "local": {
        "endpoint": "http://localhost:11434",
        "model": "llama3.1:8b"
      }
    }
  }
}
```

### Privacy Model

```
┌─────────────────────────────────────────────────────────────┐
│                    Privacy Levels                            │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  Level 0: Offline (default)                                 │
│  - No AI features                                           │
│  - Rule-based linting only                                  │
│  - No network requests                                      │
│                                                              │
│  Level 1: Local AI                                          │
│  - Uses local LLM (Ollama, LM Studio)                      │
│  - No data leaves machine                                   │
│  - Requires local model setup                               │
│                                                              │
│  Level 2: Cloud AI (explicit opt-in)                        │
│  - Uses Claude or OpenAI API                               │
│  - CLAUDE.md content sent to API                           │
│  - No codebase sent by default                             │
│                                                              │
│  Level 3: Full Analysis (explicit opt-in)                   │
│  - Codebase snippets sent for context                      │
│  - Most intelligent suggestions                            │
│  - User must explicitly enable                              │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### Prompt Engineering

#### Generic Instruction Rewriting

```typescript
const REWRITE_PROMPT = `
You are helping improve a CLAUDE.md file (context file for Claude AI).

The following instruction is too generic:
<instruction>
{{content}}
</instruction>

Project context:
- Language: {{language}}
- Main frameworks: {{frameworks}}
- Test framework: {{testFramework}}

Rewrite this instruction to be specific and actionable. Include:
- Specific file paths when relevant
- Exact command names
- Project-specific conventions

Output only the rewritten instruction, no explanation.
`;
```

#### Missing Section Generation

```typescript
const GENERATE_SECTION_PROMPT = `
You are helping create a CLAUDE.md file for a {{language}} project.

The file is missing a "{{sectionName}}" section.

Based on this project structure:
<structure>
{{fileTree}}
</structure>

And this package.json/pyproject.toml:
<config>
{{packageConfig}}
</config>

Generate an appropriate "{{sectionName}}" section following these guidelines:
- Be specific to this project
- Include actual file paths and commands
- Keep it concise (under 500 characters)
- Use proper markdown formatting

Output only the section content (including the header).
`;
```

### Cost Management

```typescript
interface TokenBudget {
  maxInputTokens: number; // Per request
  maxOutputTokens: number; // Per request
  dailyLimit?: number; // Optional daily cap
}

const DEFAULT_BUDGET: TokenBudget = {
  maxInputTokens: 2000,
  maxOutputTokens: 1000,
  dailyLimit: 10000,
};

class CostTracker {
  private usage = { input: 0, output: 0 };

  track(input: number, output: number): void;
  isWithinBudget(): boolean;
  getEstimatedCost(): number;
}
```

## Alternatives Considered

### 1. No AI Integration

**Pros**: Simpler, no API dependencies, no cost
**Cons**: Limited improvement suggestions, can't handle nuanced cases
**Decision**: Rejected - AI adds significant value for CLAUDE.md optimization

### 2. AI-Only Approach

**Pros**: More intelligent, fewer false positives
**Cons**: Requires API keys, costs money, slower
**Decision**: Rejected - Rule-based should remain primary, AI enhances

### 3. Fine-tuned Model

**Pros**: More consistent, potentially cheaper
**Cons**: Training cost, maintenance burden, less flexible
**Decision**: Rejected - General models with good prompts are sufficient

### 4. Embedding-Based Suggestions

**Pros**: Fast, local, no API needed
**Cons**: Less intelligent, requires training data
**Decision**: May add later for section similarity matching

## Implementation Plan

### Phase 1: Provider Infrastructure

```typescript
// src/ai/AIProvider.ts
export interface AIProvider {
  name: string;
  suggest(context: AIContext): Promise<Suggestion[]>;
  rewrite(content: string, instruction: string): Promise<string>;
  isConfigured(): boolean;
}

// src/ai/providers/ClaudeProvider.ts
export class ClaudeProvider implements AIProvider {
  constructor(apiKey: string, model?: string);
}

// src/ai/providers/LocalProvider.ts
export class LocalProvider implements AIProvider {
  constructor(endpoint: string, model: string);
}
```

### Phase 2: Suggest Command

```typescript
// src/cli/commands/suggest.ts
export const suggestCommand = new Command('suggest')
  .description('Get AI-powered suggestions for improving CLAUDE.md')
  .argument('<file>', 'Path to CLAUDE.md')
  .option('--generate-missing', 'Generate content for missing sections')
  .option('--rewrite-generic', 'Rewrite generic instructions')
  .option('--with-codebase', 'Include codebase context')
  .option('--provider <name>', 'AI provider to use', 'claude')
  .action(async (file, options) => {
    // Implementation
  });
```

### Phase 3: Analyze Command

```typescript
// src/cli/commands/analyze.ts
export const analyzeCommand = new Command('analyze')
  .description('Analyze codebase and suggest CLAUDE.md content')
  .argument('[dir]', 'Directory to analyze', '.')
  .option('-o, --output <file>', 'Output file for generated content')
  .option('--provider <name>', 'AI provider to use', 'claude')
  .action(async (dir, options) => {
    // Implementation
  });
```

### Phase 4: Integration with Lint

Add `--ai` flag to lint command for AI-enhanced fixes.

## Consequences

### Positive Consequences

- **Intelligent suggestions**: Context-aware improvements
- **Time savings**: Auto-generate missing sections
- **Learning tool**: AI explanations help users understand best practices
- **Competitive advantage**: Unique value proposition

### Negative Consequences

- **API dependency**: Requires external service for full features
- **Cost**: API calls cost money
- **Latency**: AI requests add delay
- **Complexity**: More code to maintain

### Neutral Consequences

- Core linting remains rule-based and fast
- Users can choose their privacy level
- Local LLM option provides offline capability

## Security Considerations

1. **API key storage**: Never store in config files, use env vars
2. **Content sent**: Clear documentation of what's sent to APIs
3. **No auto-send**: Never send codebase without explicit flag
4. **Audit log**: Log what content was sent (locally)

## Follow-up Actions

- [ ] Create AIProvider interface
- [ ] Implement ClaudeProvider
- [ ] Implement LocalProvider (Ollama)
- [ ] Build suggest command
- [ ] Build analyze command
- [ ] Add --ai flag to lint
- [ ] Write privacy documentation
- [ ] Add cost tracking

## References

- [Anthropic API Documentation](https://docs.anthropic.com/claude/docs)
- [Ollama API](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [Token Counting Best Practices](https://docs.anthropic.com/claude/docs/token-counting)
- Related ADRs: [007-v0.7.0-developer-experience](./007-v0.7.0-developer-experience.md), [008-v0.8.0-lsp-integration](./008-v0.8.0-lsp-integration.md)
